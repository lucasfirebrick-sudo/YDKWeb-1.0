#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº§å“åˆ—è¡¨é¡µä¸è¯¦æƒ…é¡µå›¾ç‰‡ä¸€è‡´æ€§ä¿®å¤è„šæœ¬
è§£å†³ç”¨æˆ·ä»åˆ—è¡¨é¡µç‚¹å‡»è¿›å…¥è¯¦æƒ…é¡µçœ‹åˆ°ä¸åŒå›¾ç‰‡çš„é—®é¢˜
"""

import os
import re
import json
from bs4 import BeautifulSoup

def main():
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    products_html = os.path.join(base_dir, 'products.html')
    products_dir = os.path.join(base_dir, 'products')
    images_dir = os.path.join(base_dir, 'images', 'products')

    print("ğŸ” åˆ†æäº§å“åˆ—è¡¨é¡µä¸è¯¦æƒ…é¡µå›¾ç‰‡ä¸€è‡´æ€§...")

    # è§£æäº§å“åˆ—è¡¨é¡µçš„å›¾ç‰‡é…ç½®
    product_list_images = extract_product_list_images(products_html)
    print(f"ğŸ“‹ äº§å“åˆ—è¡¨é¡µå‘ç° {len(product_list_images)} ä¸ªäº§å“å›¾ç‰‡")

    # åˆ†æè¯¦æƒ…é¡µå›¾ç‰‡é…ç½®
    detail_page_images = analyze_detail_pages(products_dir)
    print(f"ğŸ“„ è¯¦æƒ…é¡µåˆ†æå®Œæˆï¼Œå…± {len(detail_page_images)} ä¸ªäº§å“")

    # æ‰¾å‡ºä¸åŒ¹é…çš„äº§å“
    mismatches = find_image_mismatches(product_list_images, detail_page_images)
    print(f"âš ï¸  å‘ç° {len(mismatches)} ä¸ªå›¾ç‰‡ä¸åŒ¹é…çš„äº§å“")

    # ä¿®å¤ä¸åŒ¹é…é—®é¢˜
    fix_results = fix_image_mismatches(mismatches, products_dir, images_dir)

    # è¾“å‡ºä¿®å¤æŠ¥å‘Š
    print_fix_report(fix_results)

def extract_product_list_images(products_html_path):
    """æå–äº§å“åˆ—è¡¨é¡µçš„å›¾ç‰‡é…ç½®"""
    product_images = {}

    with open(products_html_path, 'r', encoding='utf-8') as f:
        content = f.read()

    soup = BeautifulSoup(content, 'html.parser')

    # æŸ¥æ‰¾æ‰€æœ‰äº§å“å¡ç‰‡
    product_cards = soup.find_all('div', class_='product-card')

    for card in product_cards:
        # è·å–äº§å“é“¾æ¥
        href = card.get('data-original-href', '')
        if not href:
            continue

        # æå–äº§å“ID
        product_id = href.replace('products/', '').replace('.html', '')

        # è·å–äº§å“å›¾ç‰‡
        img = card.find('img')
        if img and img.get('src'):
            img_src = img['src'].replace('images/products/', '')
            product_images[product_id] = {
                'list_image': img_src,
                'alt': img.get('alt', ''),
                'href': href
            }

    return product_images

def analyze_detail_pages(products_dir):
    """åˆ†æè¯¦æƒ…é¡µçš„å›¾ç‰‡é…ç½®"""
    detail_images = {}

    for filename in os.listdir(products_dir):
        if not filename.endswith('.html'):
            continue

        product_id = filename.replace('.html', '')
        filepath = os.path.join(products_dir, filename)

        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        # æŸ¥æ‰¾data-imagesé…ç½®
        data_images_match = re.search(r'data-images="([^"]*)"', content)
        main_image_match = re.search(r'<img[^>]*src="([^"]*)"[^>]*class="main-image"', content)

        detail_images[product_id] = {
            'has_data_images': bool(data_images_match),
            'data_images': data_images_match.group(1) if data_images_match else '',
            'main_image': main_image_match.group(1) if main_image_match else '',
            'filepath': filepath
        }

    return detail_images

def find_image_mismatches(list_images, detail_images):
    """æ‰¾å‡ºå›¾ç‰‡ä¸åŒ¹é…çš„äº§å“"""
    mismatches = []

    for product_id, list_data in list_images.items():
        if product_id not in detail_images:
            continue

        detail_data = detail_images[product_id]
        list_img = list_data['list_image']

        # æ£€æŸ¥è¯¦æƒ…é¡µæ˜¯å¦åŒ…å«åˆ—è¡¨é¡µå›¾ç‰‡
        data_images = detail_data['data_images']
        main_image = detail_data['main_image']

        list_img_in_detail = list_img in data_images or list_img in main_image

        if not list_img_in_detail:
            mismatches.append({
                'product_id': product_id,
                'list_image': list_img,
                'detail_data_images': data_images,
                'detail_main_image': main_image,
                'filepath': detail_data['filepath']
            })

    return mismatches

def fix_image_mismatches(mismatches, products_dir, images_dir):
    """ä¿®å¤å›¾ç‰‡ä¸åŒ¹é…é—®é¢˜"""
    fix_results = {
        'success': [],
        'failed': [],
        'skipped': []
    }

    for mismatch in mismatches:
        product_id = mismatch['product_id']
        list_image = mismatch['list_image']
        filepath = mismatch['filepath']

        print(f"\nğŸ”§ ä¿®å¤äº§å“: {product_id}")
        print(f"   åˆ—è¡¨é¡µå›¾ç‰‡: {list_image}")

        # æ£€æŸ¥åˆ—è¡¨é¡µå›¾ç‰‡æ˜¯å¦å­˜åœ¨
        list_image_path = os.path.join(images_dir, list_image)
        if not os.path.exists(list_image_path):
            print(f"   âŒ åˆ—è¡¨é¡µå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {list_image}")
            fix_results['failed'].append({
                'product_id': product_id,
                'reason': f'åˆ—è¡¨é¡µå›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {list_image}'
            })
            continue

        # è¯»å–è¯¦æƒ…é¡µå†…å®¹
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        # ä¿®å¤ç­–ç•¥ï¼šå°†åˆ—è¡¨é¡µå›¾ç‰‡æ·»åŠ åˆ°è¯¦æƒ…é¡µdata-imagesçš„ç¬¬ä¸€ä½
        success = add_list_image_to_detail_page(content, list_image, filepath)

        if success:
            fix_results['success'].append({
                'product_id': product_id,
                'list_image': list_image,
                'action': 'å·²å°†åˆ—è¡¨é¡µå›¾ç‰‡æ·»åŠ åˆ°è¯¦æƒ…é¡µè½®æ’­'
            })
            print(f"   âœ… ä¿®å¤æˆåŠŸ")
        else:
            fix_results['failed'].append({
                'product_id': product_id,
                'reason': 'æ— æ³•ä¿®æ”¹è¯¦æƒ…é¡µé…ç½®'
            })
            print(f"   âŒ ä¿®å¤å¤±è´¥")

    return fix_results

def add_list_image_to_detail_page(content, list_image, filepath):
    """å°†åˆ—è¡¨é¡µå›¾ç‰‡æ·»åŠ åˆ°è¯¦æƒ…é¡µè½®æ’­çš„ç¬¬ä¸€ä½"""
    try:
        # æŸ¥æ‰¾data-imagesé…ç½®
        data_images_pattern = r'data-images="([^"]*)"'
        match = re.search(data_images_pattern, content)

        if match:
            current_images = match.group(1)
            # ç§»é™¤è·¯å¾„å‰ç¼€ï¼Œç»Ÿä¸€æ ¼å¼
            list_image_clean = list_image.replace('../images/products/', '')
            current_images_clean = current_images.replace('../images/products/', '')

            # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«äº†
            if list_image_clean in current_images_clean:
                print(f"   ğŸ“‹ åˆ—è¡¨é¡µå›¾ç‰‡å·²åœ¨è¯¦æƒ…é¡µä¸­")
                return True

            # æ·»åŠ åˆ°ç¬¬ä¸€ä½
            new_images = f"../images/products/{list_image_clean},{current_images}"
            new_content = re.sub(data_images_pattern, f'data-images="{new_images}"', content)

            # åŒæ—¶æ›´æ–°ä¸»å›¾ç‰‡src
            main_image_pattern = r'(<img[^>]*src=")([^"]*)"([^>]*class="main-image")'
            new_content = re.sub(main_image_pattern, f'\\1../images/products/{list_image_clean}"\\3', new_content)

        else:
            # å¦‚æœæ²¡æœ‰data-imagesé…ç½®ï¼ŒæŸ¥æ‰¾main-imageå¹¶æ·»åŠ data-images
            main_image_pattern = r'(<img[^>]*src="[^"]*"[^>]*class="main-image"[^>]*)'
            match = re.search(main_image_pattern, content)

            if match:
                # åœ¨main-imageæ ‡ç­¾ä¸­æ·»åŠ data-imageså±æ€§
                img_tag = match.group(1)
                if 'data-images=' not in img_tag:
                    # æ·»åŠ data-imageså±æ€§
                    new_img_tag = img_tag.replace('class="main-image"',
                                                f'class="main-image"\n                                 data-images="../images/products/{list_image}"')
                    new_content = content.replace(img_tag, new_img_tag)
                else:
                    return True
            else:
                print(f"   âš ï¸  æœªæ‰¾åˆ°main-imageæ ‡ç­¾")
                return False

        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return True

    except Exception as e:
        print(f"   âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False

def print_fix_report(fix_results):
    """è¾“å‡ºä¿®å¤æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š ä¿®å¤ç»“æœæŠ¥å‘Š")
    print("="*60)

    print(f"âœ… ä¿®å¤æˆåŠŸ: {len(fix_results['success'])} ä¸ªäº§å“")
    for item in fix_results['success']:
        print(f"   - {item['product_id']}: {item['action']}")

    print(f"\nâŒ ä¿®å¤å¤±è´¥: {len(fix_results['failed'])} ä¸ªäº§å“")
    for item in fix_results['failed']:
        print(f"   - {item['product_id']}: {item['reason']}")

    print(f"\nâ­ï¸  è·³è¿‡å¤„ç†: {len(fix_results['skipped'])} ä¸ªäº§å“")
    for item in fix_results['skipped']:
        print(f"   - {item['product_id']}: {item['reason']}")

    success_rate = len(fix_results['success']) / (len(fix_results['success']) + len(fix_results['failed'])) * 100 if (len(fix_results['success']) + len(fix_results['failed'])) > 0 else 0
    print(f"\nğŸ¯ ä¿®å¤æˆåŠŸç‡: {success_rate:.1f}%")

if __name__ == '__main__':
    main()